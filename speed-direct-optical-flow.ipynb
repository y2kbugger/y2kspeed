{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from scipy import ndimage, stats\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optical Flow Based\n",
    "def fix_perspective(im, debugging=False):\n",
    "    h, w = im.shape\n",
    "    assert (w, h) == (640, 160) # this is tuned for a very specific crop and dashcam position\n",
    "    left = 60 # left-right adjustment\n",
    "    top = 5\n",
    "    bottom = 30\n",
    "    if debugging:\n",
    "        src_rect = np.array([\n",
    "            [245, originy+top],   [370, originy+top],\n",
    "            [0, 125],   [600, 100]],\n",
    "            dtype = \"float32\")\n",
    "        dst_rect = np.array([\n",
    "            [80-left, 0],    [330-left, 0],\n",
    "            [108-left, 840],  [320-left, 800]],\n",
    "            dtype = \"float32\")\n",
    "        M = cv2.getPerspectiveTransform(src_rect, dst_rect)\n",
    "        print(repr(M))\n",
    "    else:\n",
    "        M = np.array(\n",
    "           [[-5.79976346e+00, -2.25571424e+01,  1.92672659e+03],\n",
    "            [-1.81898940e-14, -1.56260338e+02,  3.90650844e+03],\n",
    "            [ 5.42171076e-05, -1.56819369e-01,  1.00000000e+00]])\n",
    "    dst = cv2.warpPerspective(im,M,(300,840-bottom))\n",
    "    if debugging:\n",
    "        plt.rcParams['figure.figsize'] = [20, 12]\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        plt.imshow(dst)\n",
    "        plt.show()\n",
    "    return dst\n",
    "\n",
    "originy=None\n",
    "def crop(image, bottom=100, top=220):\n",
    "    # take of top and bottom\n",
    "    global originy\n",
    "    originy = image.shape[0] / 2 - top\n",
    "    return image[top:image.shape[0] - bottom,:]\n",
    "\n",
    "def mutating_base_calcs(df, n):\n",
    "    df['dx'] = df.x2 - df.x1 + 0.00001\n",
    "    df['dy'] = (df.y2 - df.y1)/n\n",
    "    df['Vf_slope'] = df.dy/df.dx\n",
    "    df['|Vf|'] = np.sqrt(df.dx**2 + df.dy**2)\n",
    "\n",
    "    df['right_direction'] = (df.y2>df.y1) & (abs(df.Vf_slope) > 3) # down and steep\n",
    "    df['good'] = df['right_direction']\n",
    "\n",
    "def analyze_lk_optical_flow_dfs(dfs):\n",
    "    xs = []\n",
    "    def analyze_df(df):\n",
    "        nonlocal xs\n",
    "        # absurd\n",
    "        #df['good'] = df['good'] & (df['|Vf|'] > 2.5)\n",
    "        df['good'] = df['good'] & (df['|Vf|'] < (37/.577)) #25 is data set max, ..577 coverts from Vf to velocity\n",
    "        \n",
    "        if sum(df['good']==True) == 0:\n",
    "            xs += [np.nan, np.nan]\n",
    "        else:\n",
    "            with np.errstate(divide='ignore',invalid='ignore'):\n",
    "                df.loc[df['good'],'z'] = stats.zscore(df.loc[df['good'],'|Vf|'])\n",
    "            df.loc[df['good']==False,'z'] = 100.0\n",
    "            df['good'] = df['good'] & (df['z'] < 1.7)\n",
    "\n",
    "            if len(df) != 0:\n",
    "                # filter out noisy \"small\" flow vectors\n",
    "                Vf_max_good = df[df['good']==True]['|Vf|'].max()\n",
    "                df['good'] = df['good'] & (df['|Vf|'] > Vf_max_good * 0.25)\n",
    "            xs.append(df.loc[df['good'],'|Vf|'].mean())\n",
    "            xs.append(df.loc[df['good'],'|Vf|'].std())\n",
    "        xs.append(df['dy'].mean())\n",
    "    overall = 0\n",
    "    for n, df in enumerate(dfs):\n",
    "        global N\n",
    "        N = n + 1\n",
    "        mutating_base_calcs(df,N)\n",
    "        analyze_df(df)\n",
    "        \n",
    "        overall += df.loc[df['good'],'|Vf|'].mean()/(len(dfs)+1)\n",
    "    \n",
    "    stacked_df = pd.concat(dfs, ignore_index=True)\n",
    "    analyze_df(stacked_df)\n",
    "    overall += stacked_df.loc[stacked_df['good'],'|Vf|'].mean()/(len(dfs)+1)\n",
    "    \n",
    "    xs.append(overall)\n",
    "\n",
    "    # 0 1 2 #n=1\n",
    "    # 3 4 5 #n=2\n",
    "    # 6 7 8 #n=3\n",
    "    # 9 10 11 #stacked\n",
    "    # 12 #overall\n",
    "    return xs\n",
    "\n",
    "def via_lk_optical_flow_multi(frame, count=3):\n",
    "    frame['optical_flow'] = []\n",
    "    dfs = []\n",
    "    for i in range(1, count+1):\n",
    "        dfs.append(optical_flow(frame['_'], frame[str(i)], frame))\n",
    "    return analyze_lk_optical_flow_dfs(dfs)\n",
    "\n",
    "def debug_optical(df,img):\n",
    "    img = image_next.copy()\n",
    "    # we lose old arrow debugging with the df approach, sorry\n",
    "    #         if right_direction:\n",
    "    #             color=255\n",
    "    #             df.loc[i,'good'] = True\n",
    "    #         else:\n",
    "    #             color=130\n",
    "    #             df.loc[i,'good'] = False\n",
    "\n",
    "    #         if debugging:\n",
    "    #             img = cv2.arrowedLine(img,(int(x1),int(y1)),(int(x2),int(y2)), color, tipLength=.3)\n",
    "    #             img = cv2.circle(img,(int(x1),int(y1)),2,color, -1)\n",
    "    if len(df) == 0:\n",
    "        print(\"no useful points\")\n",
    "    else:\n",
    "        display(df.sort_values(by='|Vf|'))       \n",
    "        bins = list(range(0,101,10))\n",
    "        plt.rcParams['figure.figsize'] = [20, 5]\n",
    "        df['|Vf|'].hist(bins=bins)\n",
    "        df[df['good']==True]['|Vf|'].hist(bins=bins)\n",
    "        plt.show()\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = [20, 12]\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners = 140,\n",
    "    qualityLevel = 0.004,\n",
    "    minDistance = 20,\n",
    "    blockSize = 9,\n",
    "    #useHarrisDetector = True,\n",
    "    )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(\n",
    "    winSize  = (15,15),\n",
    "    maxLevel = 1,\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "    )\n",
    "\n",
    "def optical_flow(image, image_next, frame, debugging=False):\n",
    "    p0 = cv2.goodFeaturesToTrack(image, mask=None, **feature_params)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image, image_next, p0, None, **lk_params)\n",
    "    \n",
    "    points = []\n",
    "    for new, old in zip(p1[st==1],p0[st==1]):\n",
    "        x1, y1 = old.ravel()\n",
    "        x2, y2 = new.ravel()\n",
    "        points.append((x1,x2,y1,y2))\n",
    "    \n",
    "    df = pd.DataFrame(data=points, columns=('x1','x2','y1','y2'))\n",
    "    if debugging:\n",
    "        debug_optical(df,img)\n",
    "\n",
    "    frame['optical_flow'].append(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process frames\n",
    "def lookahead(frames, count=3):\n",
    "    # add \"lookahead\" in keys '1', '2', ...\n",
    "    # repeats at the end to keep length len\n",
    "    fs = list()\n",
    "    def _updated_f():\n",
    "        f = fs.pop(0)\n",
    "        f.update({str(n+1):f['_'] for n, f in enumerate(fs)})\n",
    "        return f \n",
    "        \n",
    "    for f in frames:\n",
    "        fs.append(f)\n",
    "        if len(fs) > count:\n",
    "            yield _updated_f()\n",
    "\n",
    "    for _ in range(count):\n",
    "        fs.append(f)\n",
    "        yield _updated_f()\n",
    "        \n",
    "def print_frame_keys(frames):\n",
    "    for f in frames:\n",
    "        print(repr(list(f.keys())))\n",
    "        yield f\n",
    "\n",
    "def view_frames(frames):\n",
    "    for f in frames:\n",
    "        for k in f.keys():\n",
    "            try:\n",
    "                cv2.imshow(k,f[k])\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            cv2.waitKey(0)\n",
    "        except KeyboardInterrupt:\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Stopping early, KeyboardInterrupt\")\n",
    "            return\n",
    "        yield f\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def persist_raw_optical_flow(frames):\n",
    "    import os\n",
    "    path = f'./data/{int(time())}'\n",
    "    os.makedirs(path)\n",
    "    for i, f in enumerate(frames):\n",
    "        for j, df in enumerate(f['optical_flow']):\n",
    "            df: pd.DataFrame\n",
    "            df.to_pickle(os.path.join(path,f'{i}_{j}.pkl'))\n",
    "        yield f\n",
    "\n",
    "class FeatureExtractor():\n",
    "    def __init__(self):\n",
    "        self._steps = []\n",
    "\n",
    "    def add_step(self, step):\n",
    "        \"\"\"step(frames_iterator) yields-> [frame,frame,...]; you can filter or gather frames\"\"\"\n",
    "        if callable(step):\n",
    "            self._steps.append(step)\n",
    "\n",
    "    def add_processor(self, processor):\n",
    "        \"\"\"processor(img) returns-> img; frame['_'] is mutated\"\"\"\n",
    "        def _step(frames):\n",
    "            for f in frames:\n",
    "                f['_'] = processor(f['_'])\n",
    "                yield f\n",
    "        self.add_step(_step)\n",
    "\n",
    "    def add_analyzer(self, analyzer):\n",
    "        \"\"\"analyzer(frame) returns-> [x1,x2,...]; frame['_'] is forwarded untouched, features are collected\"\"\"\n",
    "        def _step(frames):\n",
    "            for f in frames:\n",
    "                f['xs'] += analyzer(f)\n",
    "                yield f\n",
    "        self.add_step(_step)\n",
    "        \n",
    "    def extract_features(self, file='../data/train.mp4'):\n",
    "        frames = self._frames(file)\n",
    "        pipeline = self._make_pipe(frames)\n",
    "        self._start = time()\n",
    "        self._last = self._start\n",
    "        X = []\n",
    "        i = 0\n",
    "        for i, f in enumerate(pipeline):\n",
    "            X.append(f['xs'])\n",
    "            self._pprogress(i)\n",
    "        self._pprogress(i,True)\n",
    "        return X\n",
    "\n",
    "    def _frames(self, file):\n",
    "        vidcap = cv2.VideoCapture(file)\n",
    "        while True:\n",
    "            success, image = vidcap.read()\n",
    "            if success:\n",
    "                yield {'orig': image, '_': image, 'xs':[]}\n",
    "            else:\n",
    "                return\n",
    "\n",
    "    def _make_pipe(self, frames):\n",
    "        pipeline = frames\n",
    "        for s in self._steps:\n",
    "            pipeline = s(pipeline)\n",
    "        return pipeline\n",
    "\n",
    "    def _pprogress(self, count, force=False):\n",
    "        if force or time()-self._last>30:\n",
    "            self._last = time()\n",
    "            print(f\"{count+1} processed in {(time()-self._start)/60:2.1f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 processed in 0.5 minutes\n",
      "988 processed in 1.0 minutes\n",
      "1616 processed in 1.5 minutes\n",
      "2281 processed in 2.0 minutes\n",
      "2947 processed in 2.5 minutes\n",
      "3585 processed in 3.0 minutes\n",
      "4271 processed in 3.5 minutes\n",
      "4971 processed in 4.0 minutes\n",
      "5605 processed in 4.5 minutes\n",
      "6285 processed in 5.0 minutes\n",
      "6964 processed in 5.5 minutes\n",
      "7631 processed in 6.0 minutes\n",
      "8294 processed in 6.5 minutes\n",
      "8979 processed in 7.0 minutes\n",
      "9658 processed in 7.5 minutes\n",
      "10326 processed in 8.0 minutes\n",
      "10978 processed in 8.5 minutes\n",
      "11639 processed in 9.0 minutes\n",
      "12291 processed in 9.5 minutes\n",
      "12960 processed in 10.0 minutes\n",
      "13622 processed in 10.5 minutes\n",
      "14278 processed in 11.0 minutes\n",
      "14958 processed in 11.5 minutes\n",
      "15615 processed in 12.0 minutes\n",
      "16301 processed in 12.5 minutes\n",
      "16962 processed in 13.0 minutes\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureExtractor()\n",
    "\n",
    "#fe.add_step(lambda g: islice(g, 17500, 20400, 1)) # limit frames (start, stop, step)\n",
    "#fe.add_step(lambda g: islice(g, 400, 420, 1)) # limit frames (start, stop, step)\n",
    "\n",
    "fe.add_processor(lambda img: crop(img, bottom=100, top=220))\n",
    "fe.add_processor(lambda img: cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
    "fe.add_processor(fix_perspective)\n",
    "fe.add_processor(lambda img: cv2.GaussianBlur(img,(7,7),0))\n",
    "\n",
    "fe.add_step(lambda frames: lookahead(frames, count=3))\n",
    "\n",
    "fe.add_analyzer(via_lk_optical_flow_multi)\n",
    "\n",
    "fe.add_step(persist_raw_optical_flow)\n",
    "#fe.add_step(print_frame_keys)\n",
    "#fe.add_step(view_frames)\n",
    "\n",
    "xs = fe.extract_features('../data/train.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('../data/train.txt', header=None)\n",
    "X = pd.DataFrame(xs)\n",
    "#X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(df):\n",
    "    df.fillna(df.rolling(10,min_periods=1,win_type='nuttall').mean(), inplace=True)\n",
    "    df.fillna(method='pad', inplace=True)\n",
    "fill_nan(X)\n",
    "#X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = X.copy()\n",
    "Xy['y'] = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smooth based on distribution of acceleration in training set\n",
    "idea use kalman filter based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune a kalman filter\n",
    "from pykalman import KalmanFilter\n",
    "em_vars = [\n",
    "     #'transition_covariance',\n",
    "     'observation_covariance',\n",
    "     'initial_state_mean', 'initial_state_covariance']\n",
    "\n",
    "T = np.array([[.001]]) # smaller is more resistance to acceleration\n",
    "kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1, transition_covariance=T)\n",
    "#kf = kf.em(Xy2.loc[Xy2_train_ix,'y'].values, n_iter=0, em_vars=em_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean(|Vf|) stdev(|Vf|) mean(dy)\n",
    "# 0  1  2   #n=1\n",
    "# 3  4  5   #n=2\n",
    "# 6  7  8   #n=3\n",
    "# 9  10 11  #stacked\n",
    "# 12        #overall\n",
    "\n",
    "y_pred_col = 12\n",
    "velocity_per_vf = .577\n",
    "\n",
    "def filter_scaled_cloud_for_stop(series):\n",
    "    def a(span):\n",
    "        height_thresh = 2.6\n",
    "        fraction_under_thresh_required = 1/6.8\n",
    "        return sum((span < height_thresh)) > (len(span)*fraction_under_thresh_required)\n",
    "    def b(span):\n",
    "        height_thresh = 2.6\n",
    "        fraction_under_thresh_required = 1/6.8\n",
    "        return np.std(span) > 7.5\n",
    "    almost_stopped_mask = series.rolling(165,center=True, min_periods=1).apply(a)\n",
    "    stopped_mask = series.rolling(165,center=True, min_periods=1).apply(b) * almost_stopped_mask\n",
    "    going  = series * (almost_stopped_mask==False)\n",
    "    \n",
    "    return ((.5+np.log(series))*almost_stopped_mask + going)/(stopped_mask*5+1)\n",
    "\n",
    "def kf_and_scale(df):\n",
    "    df['y_pred_scaled'] = df[y_pred_col] * velocity_per_vf\n",
    "    df['y_pred_scaled_stop'] = filter_scaled_cloud_for_stop(df['y_pred_scaled'])\n",
    "    df.loc[df['y_pred_scaled_stop'] < 0, 'y_pred_scaled_stop'] = 0\n",
    "    df['y_pred_kf'] = kf.smooth(df['y_pred_scaled_stop'].values)[0]\n",
    "    \n",
    "\n",
    "kf_and_scale(Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [100, 12]\n",
    "plt.gca().set_xlim((0,len(Xy)))\n",
    "\n",
    "def plot(df, ix_mask, column, **kwargs):\n",
    "    try:\n",
    "        if ix_mask is None:\n",
    "            df = df.loc[:,column]\n",
    "        else:\n",
    "            df = df.loc[ix_mask, column]\n",
    "        plt.plot(df.index, df.values, **kwargs)\n",
    "    except KeyError:\n",
    "        print(f\"Skipping {column}\")\n",
    "    \n",
    "plot(Xy, None, 'y_pred_scaled', marker='o', linewidth=0.0, color='yellow', alpha=.1)\n",
    "plot(Xy, None, 'y_pred_kf', marker='', linewidth=1.5, color='green')\n",
    "plot(Xy, None, 'y', marker='', linewidth=1.7, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = ((Xy['y'] - Xy['y_pred_kf'])**2).mean()\n",
    "print(f\"MSE\\n{err:0.1f}\", end='\\t') # 10.3 was best, gaussian made it 7.2, 3.4 with tweaks to Flow Vector filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test = fe.extract_features(file='../data/test.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(xs_test)\n",
    "fill_nan(X_test)\n",
    "kf_and_scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_xlim((0,len(X_test)))\n",
    "plt.gca().set_ylim((0,25))\n",
    "plot(Xy, None, 'y_pred_scaled', marker='o', linewidth=0.0, color='yellow', alpha=.1)\n",
    "plot(Xy, None, 'y_pred_kf', marker='', linewidth=1.5, color='green')\n",
    "plot(Xy, None, 'y', marker='', linewidth=1.7, color='red')\n",
    "plot(Xy, None, 'fixed', marker='', linewidth=1.5, color='blue')\n",
    "plt.show()\n",
    "plt.gca().set_xlim((0,len(X_test)))\n",
    "plt.gca().set_ylim((0,25))\n",
    "plot(X_test, None, 'y_pred_scaled', marker='o', linewidth=0.0, color='yellow', alpha=.1)\n",
    "plot(X_test, None, 'y_pred_kf', marker='', linewidth=1.5, color='green')\n",
    "plot(X_test, None, 'fixed', marker='', linewidth=1.5, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result(series):\n",
    "    path = f'{int(time())}_msetrain:{err:0.1f}_test.txt'\n",
    "    series.apply(lambda f: f\"{f:0.6f}\").to_csv(path, index=False, header=False)\n",
    "    with open(path, 'ab') as dst:\n",
    "        dst.seek(-1, os.SEEK_END)\n",
    "        dst.truncate()\n",
    "write_result(X_test['y_pred_kf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!md5sum ll.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!md5sum ../data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
