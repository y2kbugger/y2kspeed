{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "from time import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur/focus based\n",
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def tile(im, nrows=1, ncolumns=6, debugging=False):\n",
    "    M = im.shape[0] // nrows\n",
    "    N = im.shape[1] // ncolumns\n",
    "    rows = []\n",
    "    for x in range(0, M*nrows,M):\n",
    "        row = []\n",
    "        for y in range(0,N*ncolumns,N):\n",
    "            row.append(im[x:x+M,y:y+N])\n",
    "        rows.append(row)\n",
    "    if debugging:\n",
    "        width = 3.0\n",
    "        height = width/im.shape[1]*im.shape[0]\n",
    "        fig = plt.figure(figsize = (width,height))\n",
    "        gs = gridspec.GridSpec(nrows, ncolumns, figure=fig)\n",
    "        gs.update(wspace=0.0, hspace=0.0)\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncolumns):\n",
    "                ax = fig.add_subplot(gs[r, c])\n",
    "                ax.imshow(rows[r][c], vmin=0, vmax=im.max())\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.show()\n",
    "            \n",
    "    return rows\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def via_variance_of_laplacian(f):\n",
    "    image = f['_']\n",
    "    tiles = tile(image, nrows=3, ncolumns=1)\n",
    "    return [variance_of_laplacian(i) for i in flatten(tiles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optical Flow Based\n",
    "def fix_perspective(im, debugging=False):\n",
    "    h, w = im.shape\n",
    "    assert (w, h) == (640, 160) # this is tuned for a very specific crop and dashcam position\n",
    "    left = 60 # left-right adjustment\n",
    "    top = 5\n",
    "    bottom = 30\n",
    "    if debugging:\n",
    "        src_rect = np.array([\n",
    "            [245, originy+top],   [370, originy+top],\n",
    "            [0, 125],   [600, 100]],\n",
    "            dtype = \"float32\")\n",
    "        dst_rect = np.array([\n",
    "            [80-left, 0],    [330-left, 0],\n",
    "            [108-left, 840],  [320-left, 800]],\n",
    "            dtype = \"float32\")\n",
    "        M = cv2.getPerspectiveTransform(src_rect, dst_rect)\n",
    "        print(repr(M))\n",
    "    else:\n",
    "        M = np.array(\n",
    "           [[-5.79976346e+00, -2.25571424e+01,  1.92672659e+03],\n",
    "            [-1.81898940e-14, -1.56260338e+02,  3.90650844e+03],\n",
    "            [ 5.42171076e-05, -1.56819369e-01,  1.00000000e+00]])\n",
    "    dst = cv2.warpPerspective(im,M,(300,840-bottom))\n",
    "    if debugging:\n",
    "        plt.rcParams['figure.figsize'] = [20, 12]\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        plt.imshow(dst)\n",
    "        plt.show()\n",
    "    return dst\n",
    "\n",
    "def via_lk_optical_flow(frame):\n",
    "    return optical_flow(frame['_'], frame['1'])\n",
    "\n",
    "def via_lk_optical_flow_multi(frame):\n",
    "    xs = []\n",
    "    for i in range(1,4):\n",
    "        xs += optical_flow(frame['_'], frame[str(i)], frame)\n",
    "    return xs\n",
    "\n",
    "def optical_flow(image, image_next, frame, debugging=False):\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict(\n",
    "        maxCorners = 100,\n",
    "        qualityLevel = 0.007,\n",
    "        minDistance = 20,\n",
    "        blockSize = 9,\n",
    "        #useHarrisDetector = True,\n",
    "        )\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict(\n",
    "        winSize  = (15,15),\n",
    "        maxLevel = 1,\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "        )\n",
    "    \n",
    "    p0 = cv2.goodFeaturesToTrack(image, mask=None, **feature_params)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image, image_next, p0, None, **lk_params)\n",
    "    \n",
    "    img = image_next.copy()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i,(new,old) in enumerate(zip(p1[st==1],p0[st==1])):\n",
    "        x1, y1 = old.ravel()\n",
    "        x2, y2 = new.ravel()\n",
    "        \n",
    "        dx, dy = (x2-x1), (y2-y1)\n",
    "        if dx == 0.0:\n",
    "            dx = 0.00001 #prevent divide by zero\n",
    "        Vf_slope = dy/dx\n",
    "        Vf_mag = (dx**2 + dy**2)**0.5\n",
    "        \n",
    "        if Vf_mag < 2.5 or Vf_mag>210:\n",
    "            # absurd\n",
    "            continue\n",
    "\n",
    "        df.loc[i,'|Vf|'] = Vf_mag\n",
    "        df.loc[i,'Vf_slope'] = Vf_slope\n",
    "        \n",
    "        right_direction = y2>y1 and abs(Vf_slope) > 3 # down and steep\n",
    "        df.loc[i,'right_direction'] = right_direction\n",
    "        \n",
    "        if right_direction:\n",
    "            color=255\n",
    "            df.loc[i,'good'] = True\n",
    "        else:\n",
    "            color=130\n",
    "            df.loc[i,'good'] = False\n",
    "        \n",
    "        if debugging:\n",
    "            img = cv2.arrowedLine(img,(int(x1),int(y1)),(int(x2),int(y2)), color, tipLength=.3)\n",
    "            img = cv2.circle(img,(int(x1),int(y1)),2,color, -1)\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        # filter out noisy \"small\" flow vectors\n",
    "        Vf_max = df[df['good']==True]['|Vf|'].max()\n",
    "        df.loc[df['|Vf|']<Vf_max*.45,'good'] = False\n",
    "    \n",
    "    if debugging:\n",
    "        if len(df) == 0:\n",
    "            print(\"no useful points\")\n",
    "        else:\n",
    "            display(df.sort_values(by='|Vf|'))       \n",
    "            bins = list(range(0,101,10))\n",
    "            plt.rcParams['figure.figsize'] = [20, 5]\n",
    "            df['|Vf|'].hist(bins=bins)\n",
    "            df[df['good']==True]['|Vf|'].hist(bins=bins)\n",
    "            plt.show()\n",
    "\n",
    "        plt.rcParams['figure.figsize'] = [20, 12]\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return [np.nan, np.nan]\n",
    "    else:\n",
    "        return [\n",
    "            df.loc[df['good'],'|Vf|'].mean(),\n",
    "            df.loc[df['right_direction'],'|Vf|'].std(),\n",
    "            #df.loc[df['right_direction'],'|Vf|'].count()/(0.000001+df.loc[df['right_direction']==False,'|Vf|'].count()),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff based for stop detect\n",
    "def via_diff(f):\n",
    "    return [abs(cv2.subtract(f['_'],f['1']).sum())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process frames\n",
    "def frames():\n",
    "    vidcap = cv2.VideoCapture('../data/train.mp4')\n",
    "    while True:\n",
    "        success, image = vidcap.read()\n",
    "        if success:\n",
    "            yield {'orig': image, '_': image, 'xs':[]}\n",
    "        else:\n",
    "            return\n",
    "\n",
    "originy=None\n",
    "def crop(image, bottom=100, top=220):\n",
    "    # take of top and bottom\n",
    "    global originy\n",
    "    originy = image.shape[0] / 2 - top\n",
    "    return image[top:image.shape[0] - bottom,:]\n",
    "\n",
    "def lookahead(frames, count=3):\n",
    "    # add \"lookahead\" in keys '1', '2', ...\n",
    "    # repeats at the end to keep length len\n",
    "    fs = list()\n",
    "    \n",
    "    def _updated_f():\n",
    "        f = fs.pop(0)\n",
    "        f.update({str(n+1):f['_'] for n, f in enumerate(fs)})\n",
    "        return f \n",
    "        \n",
    "    for f in frames:\n",
    "        fs.append(f)\n",
    "        if len(fs) > count:\n",
    "            yield _updated_f()\n",
    "\n",
    "    for _ in range(count):\n",
    "        fs.append(f)\n",
    "        yield _updated_f()\n",
    "        \n",
    "def print_frame_keys(frames):\n",
    "    for f in frames:\n",
    "        print(repr(list(f.keys())))\n",
    "        yield f\n",
    "\n",
    "def view_frames(frames):\n",
    "    for f in frames:\n",
    "        for k in f.keys():\n",
    "            if k == 'xs':\n",
    "                continue\n",
    "            cv2.imshow(k,f[k])\n",
    "        try:\n",
    "            cv2.waitKey(0)\n",
    "        except KeyboardInterrupt:\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Stopping early, KeyboardInterrupt\")\n",
    "            return\n",
    "        yield f\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "class FeatureExtractor():\n",
    "    def __init__(self, frames_generator_maker):\n",
    "        self._frames = frames_generator_maker\n",
    "        self._steps = []\n",
    "    def add_step(self, step):\n",
    "        \"\"\"step(frames_iterator) yields-> [frame,frame,...]; you can filter or gather frames\"\"\"\n",
    "        if callable(step):\n",
    "            self._steps.append(step)\n",
    "    def add_processor(self, processor):\n",
    "        \"\"\"processor(img) returns-> img; frame['_'] is mutated\"\"\"\n",
    "        def _step(frames):\n",
    "            for f in frames:\n",
    "                f['_'] = processor(f['_'])\n",
    "                yield f\n",
    "        self.add_step(_step)\n",
    "    def add_analyzer(self, analyzer):\n",
    "        \"\"\"analyzer(frame) returns-> [x1,x2,...]; frame['_'] is forwarded untouched, features are collected\"\"\"\n",
    "        def _step(frames):\n",
    "            for f in frames:\n",
    "                f['xs'] += analyzer(f)\n",
    "                yield f\n",
    "        self.add_step(_step)\n",
    "\n",
    "    def __iter__(self):\n",
    "        pipeline = self._frames()\n",
    "        for s in self._steps:\n",
    "            pipeline = s(pipeline)\n",
    "        return pipeline\n",
    "    def _pprogress(self, count, force=False):\n",
    "        if force or time()-self._last>30:\n",
    "            self._last = time()\n",
    "            print(f\"{count+1} processed in {(time()-self._start)/60:2.1f} minutes\")\n",
    "    def extract_features(self):\n",
    "        self._start = time()\n",
    "        self._last = self._start\n",
    "        X = []\n",
    "        i=0\n",
    "        for i, f in enumerate(self):\n",
    "            X.append(f['xs'])\n",
    "            self._pprogress(i)\n",
    "        self._pprogress(i,True)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FeatureExtractor' object has no attribute 'add_processor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-0f51072a76e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#fe.add_step(lambda g: islice(g, 17500, 20400, 1)) # limit frames (start, stop, step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#fe.add_step(lambda g: islice(g, 400, 420, 1)) # limit frames (start, stop, step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m220\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfix_perspective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FeatureExtractor' object has no attribute 'add_processor'"
     ]
    }
   ],
   "source": [
    "fe = FeatureExtractor(frames)\n",
    "#fe.add_step(lambda g: islice(g, 17500, 20400, 1)) # limit frames (start, stop, step)\n",
    "#fe.add_step(lambda g: islice(g, 400, 420, 1)) # limit frames (start, stop, step)\n",
    "fe.add_processor(lambda img: crop(img, bottom=100, top=220))\n",
    "fe.add_processor(lambda img: cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
    "fe.add_processor(fix_perspective)\n",
    "fe.add_processor(lambda img: cv2.GaussianBlur(img,(7,7),0))\n",
    "\n",
    "fe.add_step(lambda frames: lookahead(frames, count = 3))\n",
    "\n",
    "#fe.add_analyzer(via_lk_optical_flow)\n",
    "fe.add_analyzer(via_lk_optical_flow_multi)\n",
    "fe.add_analyzer(via_variance_of_laplacian)\n",
    "fe.add_analyzer(via_diff)\n",
    "\n",
    "#fe.add_step(print_frame_keys)\n",
    "#fe.add_step(view_frames)\n",
    "\n",
    "xs = fe.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_time_in_chunks(df, n):\n",
    "    \"\"\"Break df into n-lengths mini dfs\"\"\"\n",
    "    assert len(df) >= n*10, \"doesn't meet minimum number of chunks\"\n",
    "    assert (len(df) % n) == 0, \"all chunks equal size\"\n",
    "    \n",
    "    chunk_count = len(df[0]) // n\n",
    "    chunks = []\n",
    "    for x in range(0, len(df), n):\n",
    "        chunks.append(df[x:x + n])\n",
    "    random.shuffle(chunks)\n",
    "    print(f\"Using {len(chunks):0d} chunks\")\n",
    "    return pd.concat(chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19866.000000</td>\n",
       "      <td>19661.000000</td>\n",
       "      <td>20036.000000</td>\n",
       "      <td>19878.000000</td>\n",
       "      <td>20103.000000</td>\n",
       "      <td>19953.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.552824</td>\n",
       "      <td>10.004576</td>\n",
       "      <td>52.972476</td>\n",
       "      <td>18.957712</td>\n",
       "      <td>68.300896</td>\n",
       "      <td>25.140959</td>\n",
       "      <td>8.408135</td>\n",
       "      <td>16.742233</td>\n",
       "      <td>27.722560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.324659</td>\n",
       "      <td>7.447554</td>\n",
       "      <td>31.596921</td>\n",
       "      <td>12.423549</td>\n",
       "      <td>35.995528</td>\n",
       "      <td>14.638649</td>\n",
       "      <td>7.849372</td>\n",
       "      <td>20.646390</td>\n",
       "      <td>22.533583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.509902</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>2.518085</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>2.539756</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.445136</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>1.101333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.878727</td>\n",
       "      <td>4.294807</td>\n",
       "      <td>25.361583</td>\n",
       "      <td>8.668864</td>\n",
       "      <td>36.572500</td>\n",
       "      <td>12.888479</td>\n",
       "      <td>3.722191</td>\n",
       "      <td>6.599687</td>\n",
       "      <td>13.593769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.993662</td>\n",
       "      <td>8.209656</td>\n",
       "      <td>49.432547</td>\n",
       "      <td>16.800758</td>\n",
       "      <td>69.286232</td>\n",
       "      <td>24.110843</td>\n",
       "      <td>6.461624</td>\n",
       "      <td>11.257055</td>\n",
       "      <td>22.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.298911</td>\n",
       "      <td>13.975738</td>\n",
       "      <td>80.117981</td>\n",
       "      <td>27.995923</td>\n",
       "      <td>101.009919</td>\n",
       "      <td>36.900552</td>\n",
       "      <td>10.014634</td>\n",
       "      <td>18.339421</td>\n",
       "      <td>34.122489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>139.708016</td>\n",
       "      <td>73.634299</td>\n",
       "      <td>139.911574</td>\n",
       "      <td>91.726222</td>\n",
       "      <td>139.977520</td>\n",
       "      <td>85.884460</td>\n",
       "      <td>79.624204</td>\n",
       "      <td>247.244385</td>\n",
       "      <td>281.267529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  19866.000000  19661.000000  20036.000000  19878.000000  20103.000000   \n",
       "mean      30.552824     10.004576     52.972476     18.957712     68.300896   \n",
       "std       21.324659      7.447554     31.596921     12.423549     35.995528   \n",
       "min        2.509902      0.004829      2.518085      0.006849      2.539756   \n",
       "25%       13.878727      4.294807     25.361583      8.668864     36.572500   \n",
       "50%       26.993662      8.209656     49.432547     16.800758     69.286232   \n",
       "75%       42.298911     13.975738     80.117981     27.995923    101.009919   \n",
       "max      139.708016     73.634299    139.911574     91.726222    139.977520   \n",
       "\n",
       "                  5             6             7             8  \n",
       "count  19953.000000  20400.000000  20400.000000  20400.000000  \n",
       "mean      25.140959      8.408135     16.742233     27.722560  \n",
       "std       14.638649      7.849372     20.646390     22.533583  \n",
       "min        0.002208      0.445136      0.688506      1.101333  \n",
       "25%       12.888479      3.722191      6.599687     13.593769  \n",
       "50%       24.110843      6.461624     11.257055     22.300781  \n",
       "75%       36.900552     10.014634     18.339421     34.122489  \n",
       "max       85.884460     79.624204    247.244385    281.267529  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('../data/train.txt', header=None)\n",
    "X = pd.DataFrame(xs)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20036.000000</td>\n",
       "      <td>20103.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.972476</td>\n",
       "      <td>68.300896</td>\n",
       "      <td>26.219617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.596921</td>\n",
       "      <td>35.995528</td>\n",
       "      <td>14.778141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.518085</td>\n",
       "      <td>2.539756</td>\n",
       "      <td>1.640342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.361583</td>\n",
       "      <td>36.572500</td>\n",
       "      <td>13.469342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.432547</td>\n",
       "      <td>69.286232</td>\n",
       "      <td>25.220742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.117981</td>\n",
       "      <td>101.009919</td>\n",
       "      <td>38.581864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>139.911574</td>\n",
       "      <td>139.977520</td>\n",
       "      <td>77.770879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  2             4           024\n",
       "count  20036.000000  20103.000000  20400.000000\n",
       "mean      52.972476     68.300896     26.219617\n",
       "std       31.596921     35.995528     14.778141\n",
       "min        2.518085      2.539756      1.640342\n",
       "25%       25.361583     36.572500     13.469342\n",
       "50%       49.432547     69.286232     25.220742\n",
       "75%       80.117981    101.009919     38.581864\n",
       "max      139.911574    139.977520     77.770879"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['024'] = (Xy2[0] + Xy2[2]/2 + Xy2[4]/3)/3 # add \"theoretical average\"\n",
    "#X.drop(labels=[1,3,5,6,7,8], axis=1, inplace=True) # remove std and blur\n",
    "#X.drop(labels=[1,5,6,7,8], axis=1, inplace=True) # leave 1 std and 0 blur\n",
    "#X.drop(labels=[1,3,5], axis=1, inplace=True) # just remove std\n",
    "X.drop(labels=[0,1,3,5,6,7,8], axis=1, inplace=True) # just remove varlaplace\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([2, 4, '024'], dtype='object')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-e8516ddcfb4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2040\u001b[0m \u001b[0;31m# ten chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m204\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;31m# 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mXy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle_time_in_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6abf0505188b>\u001b[0m in \u001b[0;36mshuffle_time_in_chunks\u001b[0;34m(df, n)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all chunks equal size\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mchunk_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "X.fillna(method='pad', inplace=True)\n",
    "\n",
    "Xy = X.copy(deep=True)\n",
    "Xy['y'] = y\n",
    "\n",
    "chunksize = 60\n",
    "chunksize = 2040 # ten chunks\n",
    "chunksize = 204*2 # 50\n",
    "Xy = shuffle_time_in_chunks(Xy, chunksize)\n",
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_testcount(test_df, fraction_testset=0.3):\n",
    "    chunks = 1\n",
    "    while True:\n",
    "        chunks += 1\n",
    "        testcount = chunksize * chunks\n",
    "        if testcount/len(test_df)>fraction_testset:\n",
    "            break\n",
    "    print(f\"using testcount = {testcount}\")\n",
    "    return testcount\n",
    "    \n",
    "testcount = find_testcount(Xy, .43)\n",
    "\n",
    "Xy_train, Xy_test = train_test_split(Xy, test_size=testcount,shuffle=False)\n",
    "Xy_train, Xy_test = Xy_train.copy(deep=True), Xy_test.copy(deep=True)\n",
    "print(\"Percent test    =\", testcount/len(Xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "m_dum = DummyRegressor(strategy='mean')\n",
    "\n",
    "m_ensemble = StackingRegressor([\n",
    "   ('svr', SVR(C=.3)),\n",
    "   ('rf', RandomForestRegressor(n_estimators=60)),\n",
    "   #('mlp', MLPRegressor(shuffle=False, alpha=0.1)),\n",
    "   ])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    #('poly', PolynomialFeatures(interaction_only=False, include_bias=False)),\n",
    "    #'reduce_dims', PCA(n_components=4)),\n",
    "    #('svr', SVR(C=2)),\n",
    "    #('rf', RandomForestRegressor()),\n",
    "    #'mlp', MLPRegressor(shuffle=False, alpha=0.1)),\n",
    "    #('br', BayesianRidge()),\n",
    "    ('stack', m_ensemble),\n",
    "    #('lin', LinearRegression()),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "# # Training classifiers\n",
    "# reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "# reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "# reg3 = LinearRegression()\n",
    "# ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "# BaysianRidge\n",
    "# MLP NN\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'stack__svr__C':[.01, .1, .3, .9, 2, 4, 10, 15, 20, 50, 100, 600],\n",
    "    'stack__rf__n_estimators': [20, 50, 100, 150],\n",
    "    #'stack__rf__max_depth': None,\n",
    "    \n",
    "    #'svr__C':[10, 20, 30, 40, 70, 120],\n",
    "    #'mlp__alpha':[0.0001, 0.001, 0.01],\n",
    "    #'svr__C':[.3],RandomForestRegressor\n",
    "    #'svr__gamma':[0.006/4, 0.006/2,0.006,0.006*2],\n",
    "    }\n",
    "grid = GridSearchCV(pipe, parameters, verbose=10, n_jobs=5, cv=5)\n",
    "\n",
    "m_real = pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dum.fit(Xy_train[X.columns], Xy_train['y'])\n",
    "m_real.fit(Xy_train[X.columns], Xy_train['y'])\n",
    "try:\n",
    "    print(m_real.best_estimator_)\n",
    "except:\n",
    "    print(m_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate full original df\n",
    "Xy_test.loc[:,'is_test'] = True\n",
    "Xy_train.loc[:,'is_test'] = False\n",
    "Xy2 = pd.concat([Xy_test,Xy_train]).sort_index()\n",
    "\n",
    "# get predictions\n",
    "Xy2['dum'] = m_dum.predict(Xy2[X.columns])\n",
    "Xy2['pred'] = m_real.predict(Xy2[X.columns])\n",
    "\n",
    "# for convience\n",
    "Xy2_test_ix = Xy2['is_test'] == True\n",
    "Xy2_train_ix = Xy2['is_test'] == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smooth based on distribution of acceleration in training set\n",
    "idea use kalman filter based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune a kalman filter\n",
    "from pykalman import KalmanFilter\n",
    "em_vars = [\n",
    "     #'transition_covariance',\n",
    "     'observation_covariance',\n",
    "     'initial_state_mean', 'initial_state_covariance']\n",
    "\n",
    "T = np.array([[.0009]]) # smaller is more resistance to acceleration\n",
    "\n",
    "kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1, transition_covariance=T)\n",
    "kf_tuned = kf.em(Xy2.loc[Xy2_train_ix,'y'].values, n_iter=0, em_vars=em_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply kalman\n",
    "Xy2.loc[Xy2_test_ix,'pred_kf'] = kf_tuned.smooth(Xy2.loc[Xy2_test_ix,'pred'].values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# never below 0\n",
    "Xy2.loc[Xy2['pred_kf']<0.0,'pred_kf'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mean = Xy2.loc[Xy2_train_ix,'y'].mean()\n",
    "training_mean = Xy2['y'].mean() # for full comparison, overly optimistic though\n",
    "\n",
    "Xy2['0_kf_'] = kf_tuned.smooth(Xy2[0].values)[0]\n",
    "Xy2['0_kf'] = Xy2['0_kf_'] * training_mean/Xy2['0_kf_'].mean()\n",
    "Xy2['0_scaled'] = Xy2[0] * training_mean/Xy2[0].mean()\n",
    "\n",
    "Xy2['024_kf_'] = kf_tuned.smooth(Xy2['024'].values)[0]\n",
    "Xy2['024_kf'] = Xy2['024_kf_'] * training_mean/Xy2['024_kf_'].mean()\n",
    "Xy2['024_scaled'] = Xy2['024'] * training_mean/Xy2['024'].mean()\n",
    "\n",
    "Xy2['NoML'] = Xy2['024_kf'] # pick the best\n",
    "Xy2['NoML_raw'] = Xy2['024_scaled'] # pick the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [100, 12]\n",
    "plt.gca().set_xlim((0,len(Xy2)))\n",
    "def plot_Xy2(ix_mask, column, **kwargs):\n",
    "    if ix_mask is None:\n",
    "        df = Xy2.loc[:,column]\n",
    "    else:\n",
    "        df = Xy2.loc[ix_mask, column]\n",
    "    plt.plot(df.index, df.values, **kwargs)\n",
    "    \n",
    "#plot_Xy2(Xy2_test_ix, 'pred', marker='o', linewidth=0.0, color='green', alpha=.1)\n",
    "\n",
    "#plot_Xy2(Xy2_train_ix, 'pred', marker='o', linewidth=0.0, color='purple', alpha=.1)\n",
    "plot_Xy2(None, 'NoML_raw', marker='o', linewidth=0.0, color='yellow', alpha=.1)\n",
    "plot_Xy2(None, 'NoML', marker='', linewidth=1.5, color='orange')\n",
    "#plot_Xy2(None, 4, marker='', linewidth=0.5, color='blue')\n",
    "plot_Xy2(None, 'y', marker='', linewidth=1.4, color='red')\n",
    "plot_Xy2(Xy2_test_ix, 'pred_kf', marker='o', linewidth=0.0, color='green', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_line(ix_mask, column='dum'):\n",
    "    if ix_mask is not None:\n",
    "        Xy = Xy2[ix_mask]\n",
    "    else:\n",
    "        Xy = Xy2\n",
    "    err = mean_squared_error(Xy['y'], Xy[column])\n",
    "    print(f\"{err:0.1f}\", end='\\t')\n",
    "\n",
    "print(f\"dummy\\ttest\\ttrain\\ttest_kf\\tNoML\")\n",
    "print_summary_line(Xy2_test_ix,'dum')\n",
    "print_summary_line(Xy2_test_ix,'pred')\n",
    "print_summary_line(Xy2_train_ix,'pred')\n",
    "print_summary_line(Xy2_test_ix,'pred_kf')\n",
    "print_summary_line(None,'NoML') # 10.3 was best, gaussian made it 7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummy\ttest\ttrain\ttest_kf\tNoML   C    n_estimator\n",
    "79.1\t15.6\t4.20\t9.00\t10.8   20   150\n",
    "79.1\t15.7\t4.70\t9.10\t10.8   5    60\n",
    "79.1\t15.6\t5.20\t9.00\t10.8   2    60\n",
    "   .3    60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
