{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def frames():\n",
    "    vidcap = cv2.VideoCapture('../data/train.mp4')\n",
    "    while True:\n",
    "        success, image = vidcap.read()\n",
    "        if success:\n",
    "            yield image\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def crop(im, bottom=100, top=220):\n",
    "    # take of top and bottom\n",
    "    return im[top:im.shape[0]-bottom,:]\n",
    "\n",
    "def tile(im, nrows=1, ncolumns=6):\n",
    "    M = im.shape[0] // nrows\n",
    "    N = im.shape[1] // ncolumns\n",
    "    rows = []\n",
    "    for y in range(0,N*ncolumns,N):\n",
    "        row = []\n",
    "        for x in range(0,M*nrows,M):\n",
    "            row.append(im[x:x+M,y:y+N])\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def shuffle_time_in_chunks(df, n):\n",
    "    \"\"\"Break df into n-lengths mini dfs\"\"\"\n",
    "    assert len(df) > n*10, \"doesn't meet minimum number of chunks\"\n",
    "    assert (len(df) % n) == 0, \"all chunks equal size\"\n",
    "\n",
    "    chunk_count = len(df[0]) // n\n",
    "    chunks = []\n",
    "    for x in range(0, len(df), n):\n",
    "        chunks.append(df[x:x + n])\n",
    "    random.shuffle(chunks)\n",
    "    return pd.concat(chunks, axis=0)\n",
    "\n",
    "def quick_view(fs, frames_per_step=1, start=1000, stop=1010):\n",
    "    for i, im in enumerate(fs):\n",
    "        if not (start<i<stop):\n",
    "            if i>stop:\n",
    "                break\n",
    "            continue\n",
    "        if i % frames_per_step != 0:\n",
    "            continue\n",
    "        cv2.imshow('oned',im)\n",
    "        try:\n",
    "            cv2.waitKey(0)\n",
    "        except KeyboardInterrupt:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cframes():\n",
    "    for im in frames():\n",
    "        yield crop(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick_view(cframes(), frames_per_step=1, start=60, stop=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-315c4f3018e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# blur/focus based\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariance_of_laplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# compute the Laplacian of the image and then return the focus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# measure, which is simply the variance of the Laplacian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False\n",
    "# blur/focus based\n",
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "xs=[]\n",
    "for i, f in enumerate(cframes()):\n",
    "    tiles = tile(f,8,20)\n",
    "    xs.append([variance_of_laplacian(i) for i in flatten(tiles)])\n",
    "    if i % 1000 == 0:\n",
    "        print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[264.   8.]]\n",
      "\n",
      " [[141.   6.]]\n",
      "\n",
      " [[389.   9.]]\n",
      "\n",
      " [[367.   9.]]\n",
      "\n",
      " [[274.   8.]]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'color' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-990e2bd45eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m#xs.append([method(im, lim) for im, lim in zip(flatten(tiles),flatten(last_tiles))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m#xs.append([method(im,last_im)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-990e2bd45eea>\u001b[0m in \u001b[0;36mvia_lk\u001b[0;34m(im, last_im)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'color' is not defined"
     ]
    }
   ],
   "source": [
    "# phase correlation based\n",
    "def translation_speed_via_phase(im, last_im):\n",
    "\n",
    "    lol = cv2.phaseCorrelate(np.float32(im), np.float32(last_im))\n",
    "    #??????????? which axis?\n",
    "    print(lol[0][1])\n",
    "    print(im.shape)\n",
    "    cv2.imshow('oned',im)\n",
    "    cv2.imshow('two',last_im)\n",
    "    cv2.waitKey(0) # waits until a key is pressed]\n",
    "    return lol[0][1]\n",
    "\n",
    "# optical flow\n",
    "def translation_speed_via_optical_flow(im, last_im):\n",
    "    flow = cv2.calcOpticalFlowFarneback(last_im, im, None,\n",
    "        pyr_scale=0.5,\n",
    "        levels=2,\n",
    "        winsize=6,\n",
    "        iterations=2,\n",
    "        poly_n=5,\n",
    "        poly_sigma=1.2,\n",
    "        flags=0)\n",
    "    return cluster_velocities(flow)\n",
    "\n",
    "def via_lk(im, last_im):\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    p0 = cv2.goodFeaturesToTrack(last_im, mask = None, **feature_params)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(last_im, im, p0, None, **lk_params)\n",
    "    print(p1)\n",
    "\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(last_im)\n",
    "    \n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(), -1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "def cluster_velocities(flow):\n",
    "    dy,dx = flow[...,0], flow[...,1]\n",
    "    shape=dy.shape\n",
    "    ys,xs = np.indices(shape)\n",
    "    \n",
    "    # setup zenith\n",
    "    xs -= shape[1] // 2\n",
    "    ys += -45\n",
    "    slope = dy/dx\n",
    "    intercept = (-1*xs*slope)-ys\n",
    "    mask = ((intercept>-350.0)&(intercept<-110.0)) ==True\n",
    "\n",
    "    #cv2.imshow('intercept', intercept*mask)\n",
    "    #cv2.imshow('intercept_mask', mask*1.0)\n",
    "    #cv2.waitKey(0)\n",
    "    #return 0\n",
    "    plt.imshow(intercept*mask)\n",
    "    plt.show()\n",
    "    return 0\n",
    "    \n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    df = pd.DataFrame()\n",
    "    df['mag'] = mag.flatten()\n",
    "    df['ang'] = ang.flatten()\n",
    "    df['intercept'] = intercept.flatten()\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    df[df['intercept'].between(-300, 100)]['intercept'].plot.hist(by='intercept')\n",
    "    plt.show()\n",
    "    df[df['intercept'].between(-300, 100) & (df['mag']>2.0)]['mag'].plot.hist(by='mag')\n",
    "    plt.show()\n",
    "    return(0)\n",
    "    \n",
    "    \n",
    "    #df[df['ang'] >0.1]['ang'].plot.hist(by='ang')\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df[df['mag'] > 1]['mag'].plot.hist(by='mag')\n",
    "    plt.show()\n",
    "    return 0\n",
    "    y : np.ndarray\n",
    "    yvals = y.flatten()\n",
    "    \n",
    "\n",
    "method = translation_speed_via_optical_flow\n",
    "method = via_lk\n",
    "\n",
    "xs=[]\n",
    "last_im = None\n",
    "for i, im in enumerate(cframes()):\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    if last_im is None:\n",
    "        last_im = im\n",
    "    #rows, columns = 3, 8\n",
    "    #rows, columns = 1, 1\n",
    "    #tiles = tile(im,rows,columns)\n",
    "    #last_tiles = tile(last_im,rows,columns)\n",
    "    #xs.append([method(im, lim) for im, lim in zip(flatten(tiles),flatten(last_tiles))])\n",
    "    #xs.append([method(im,last_im)])\n",
    "    method(im,last_im)\n",
    "    if i+1 % 100 == 0:\n",
    "        print('.', end='')\n",
    "        break\n",
    "    if i == 3:\n",
    "        pass\n",
    "      \n",
    "    last_im = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xs))\n",
    "y = pd.read_csv('../data/train.txt', header=None)\n",
    "X = pd.DataFrame(xs)\n",
    "\n",
    "Xy = X.copy(deep=True)\n",
    "Xy['y'] = y\n",
    "chunksize = 240\n",
    "Xy = shuffle_time_in_chunks(Xy, chunksize)\n",
    "\n",
    "X = Xy[X.columns]\n",
    "yorig = y\n",
    "y = Xy[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_testcount(test_df, fraction_testset=0.3):\n",
    "    chunks = 1\n",
    "    while True:\n",
    "        chunks += 1\n",
    "        testcount = chunksize * chunks\n",
    "        if testcount/len(test_df)>fraction_testset:\n",
    "            break\n",
    "    print(f\"using testcount={testcount}\")\n",
    "    return testcount\n",
    "    \n",
    "testcount = find_testcount(Xy, .43)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=testcount, shuffle=False)\n",
    "print(testcount/len(Xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DummyRegressor(strategy='mean')\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        #'reduce_dims', PCA(n_components=4)),\n",
    "        ('svr', SVR())])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    #'svr__C':[.01, .1, .3, .9, 2, 4, 10, 20],\n",
    "    'svr__C':[10, 15, 20, 30, 40],\n",
    "    'svr__gamma':[0.006/4, 0.006/2,0.006,0.006*2],\n",
    "    }\n",
    "svr = GridSearchCV(pipe, parameters, verbose=10, n_jobs=7, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(Xtrain, ytrain['y'])\n",
    "svr.fit(Xtrain, ytrain['y'])\n",
    "print(svr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_pred = svr.predict(Xtest)\n",
    "ytrain_pred = svr.predict(Xtrain)\n",
    "print(f\"dummy test train\")\n",
    "print(f\"{mean_squared_error(ytest, m.predict(Xtest)):0.1f} {mean_squared_error(ytest, ytest_pred):0.1f} {mean_squared_error(ytrain, ytrain_pred):0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing error, training error\n",
    "- naive shuffle, mean dummy regressor = 68\n",
    "- naive shuffle, 1x1x(varlaplace) tilessvr.predict(Xtest), SVR(C=?) = 44\n",
    "- naive shuffle, 6x3x(varlaplace) tiles, SVR(C=30) = 19.4\n",
    "- naive shuffle, 12x5x(varlaplace) tiles, SVR(C=30) = 10.3\n",
    "- naive shuffle, test_size=.150, 26x12x(varlaplace) tiles, SVR(C=.2) = 17.9, 18.1\n",
    "-    no shuffle, test_size=.150, 26x12x(varlaplace) tiles, SVR(C=.2) = 33.2, 17.7\n",
    "- chunk shuffle, test_size=.147, 26x12x(varlaplace) tiles, SVR(C=.2) = 39, 16.6\n",
    "- chunk shuffle, test_size=.147, 26x12x(varlaplace) tiles, SVR(C=.1) = 42, 20\n",
    "- chunk shuffle, test_size=.147, 26x12x(varlaplace) tiles, SVR(C=.5) = 36, 12\n",
    "- chunk shuffle, test_size=.147, 14x06x(varlaplace) tiles, SVR(C=.5) = 27, 19\n",
    "- chunk shuffle, test_size=.147, 14x06x(varlaplace) tiles, SVR(C=.3) = 28.5, 21.5, 39.5\n",
    "- chunk shuffle, test_size=.245, 14x06x(varlaplace) tiles, SVR(C=.3) = 50, 46, 18\n",
    "# new crop\n",
    "- chunk no shuffle, test_size=.245, 14x06x(varlaplace) tiles, SVR(C=.3) = 71, 39, 26.9\n",
    "- chunk=5 shuffle, test_size=.367, 06x06x(varlaplace) tiles, SVR(C=.3) = 67, 30, 29.1\n",
    "- chunk=5 shuffle, test_size=.491, 06x06x(varlaplace) tiles, SVR(C=.3) = 67, 30, 29.7\n",
    "- chunk=5 shuffle, test_size=.73, 06x06x(varlaplace) tiles, SVR(C=.3) = 67, 32, 30.7\n",
    "\n",
    "# Fixed tiler                                             \n",
    "-                                                                dummy test train\n",
    "- chunk=60 shuffle, test_size=.43, 4x10(varlaplace), SVR(C=.3) = 70.3 39.6 29.4\n",
    "- chunk=60 shuffle, test_size=.43, 8x20(varlaplace), SVR(C=.3) = 71.6 31.1 22.6\n",
    "- chunk=60 shuffle, test_size=.43, 8x20(varlaplace), gridsearch = 71.6 31.1 22.6\n",
    "- chunk=60 focus 3x8 SVR(C=20, gamma=0.006) 64.0 13.0 2.0\n",
    "\n",
    "## ideas\n",
    "x start chunking\n",
    "- increase test_size to at least .25\n",
    "- accelleration limits based on testing set. This could be a post processing step.concat\\\n",
    "- Actually calculate the origin rather than guessing based on the crop.\n",
    "- Can we get explicitly always calculate Vr\n",
    "- Optical flow techniques for estimation of camera motion parameters insewer closed circuit television inspection videos\n",
    "  - The reference angle is in the denominator and therefore normalizes the optical flow vector.\n",
    "- Kalman:\n",
    "  - https://scipy-cookbook.readthedocs.io/items/KalmanFiltering.html\n",
    "- To apply kalman to blur based-must find way to unshuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
