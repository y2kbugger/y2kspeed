{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "from time import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from scipy import ndimage, stats\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur/focus based\n",
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def tile(im, nrows=1, ncolumns=6, debugging=False):\n",
    "    M = im.shape[0] // nrows\n",
    "    N = im.shape[1] // ncolumns\n",
    "    rows = []\n",
    "    for x in range(0, M*nrows,M):\n",
    "        row = []\n",
    "        for y in range(0,N*ncolumns,N):\n",
    "            row.append(im[x:x+M,y:y+N])\n",
    "        rows.append(row)\n",
    "    if debugging:\n",
    "        width = 3.0\n",
    "        height = width/im.shape[1]*im.shape[0]\n",
    "        fig = plt.figure(figsize = (width,height))\n",
    "        gs = gridspec.GridSpec(nrows, ncolumns, figure=fig)\n",
    "        gs.update(wspace=0.0, hspace=0.0)\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncolumns):\n",
    "                ax = fig.add_subplot(gs[r, c])\n",
    "                ax.imshow(rows[r][c], vmin=0, vmax=im.max())\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.show()\n",
    "            \n",
    "    return rows\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def via_variance_of_laplacian(f):\n",
    "    image = f['_']\n",
    "    tiles = tile(image, nrows=3, ncolumns=1)\n",
    "    return [variance_of_laplacian(i) for i in flatten(tiles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optical Flow Based\n",
    "def fix_perspective(im, debugging=False):\n",
    "    h, w = im.shape\n",
    "    assert (w, h) == (640, 160) # this is tuned for a very specific crop and dashcam position\n",
    "    left = 60 # left-right adjustment\n",
    "    top = 5\n",
    "    bottom = 30\n",
    "    if debugging:\n",
    "        src_rect = np.array([\n",
    "            [245, originy+top],   [370, originy+top],\n",
    "            [0, 125],   [600, 100]],\n",
    "            dtype = \"float32\")\n",
    "        dst_rect = np.array([\n",
    "            [80-left, 0],    [330-left, 0],\n",
    "            [108-left, 840],  [320-left, 800]],\n",
    "            dtype = \"float32\")\n",
    "        M = cv2.getPerspectiveTransform(src_rect, dst_rect)\n",
    "        print(repr(M))\n",
    "    else:\n",
    "        M = np.array(\n",
    "           [[-5.79976346e+00, -2.25571424e+01,  1.92672659e+03],\n",
    "            [-1.81898940e-14, -1.56260338e+02,  3.90650844e+03],\n",
    "            [ 5.42171076e-05, -1.56819369e-01,  1.00000000e+00]])\n",
    "    dst = cv2.warpPerspective(im,M,(300,840-bottom))\n",
    "    if debugging:\n",
    "        plt.rcParams['figure.figsize'] = [20, 12]\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        plt.imshow(dst)\n",
    "        plt.show()\n",
    "    return dst\n",
    "\n",
    "def mutating_base_calcs(df, n):\n",
    "    df['dx'] = df.x2 - df.x1 + 0.00001\n",
    "    df['dy'] = (df.y2 - df.y1)/n\n",
    "    df['Vf_slope'] = df.dy/df.dx\n",
    "    df['|Vf|'] = np.sqrt(df.dx**2 + df.dy**2)\n",
    "\n",
    "    df['right_direction'] = (df.y2>df.y1) & (abs(df.Vf_slope) > 3) # down and steep\n",
    "    df['good'] = df['right_direction']\n",
    "\n",
    "def analyze_lk_optical_flow_dfs(dfs):\n",
    "    xs = []\n",
    "    def analyze_df(df):\n",
    "        nonlocal xs\n",
    "        # absurd\n",
    "        #df['good'] = df['good'] & (df['|Vf|'] > 2.5)\n",
    "        df['good'] = df['good'] & (df['|Vf|'] < (35/.45)) #25 is data set max, .45 coverts from Vf to velocity\n",
    "        \n",
    "        if sum(df['good']==True) == 0:\n",
    "            xs += [np.nan, np.nan]\n",
    "        else:\n",
    "            with np.errstate(divide='ignore',invalid='ignore'):\n",
    "                df.loc[df['good'],'z'] = stats.zscore(df.loc[df['good'],'|Vf|'])\n",
    "            df.loc[df['good']==False,'z'] = 100.0\n",
    "            df['good'] = df['good'] & (df['z'] < 1.7)\n",
    "\n",
    "            if len(df) != 0:\n",
    "                # filter out noisy \"small\" flow vectors\n",
    "                Vf_max_good = df[df['good']==True]['|Vf|'].max()\n",
    "                df['good'] = df['good'] & (df['|Vf|'] > Vf_max_good * 0.25)\n",
    "            xs.append(df.loc[df['good'],'|Vf|'].mean())\n",
    "            xs.append(df.loc[df['good'],'|Vf|'].std())\n",
    "        xs.append(df['dy'].mean())\n",
    "    overall = 0\n",
    "    for n, df in enumerate(dfs):\n",
    "        global N\n",
    "        N = n + 1\n",
    "        mutating_base_calcs(df,N)\n",
    "        analyze_df(df)\n",
    "        \n",
    "        overall += df.loc[df['good'],'|Vf|'].mean()/(len(dfs)+1)\n",
    "    \n",
    "    stacked_df = pd.concat(dfs, ignore_index=True)\n",
    "    analyze_df(stacked_df)\n",
    "    overall += stacked_df.loc[stacked_df['good'],'|Vf|'].mean()/(len(dfs)+1)\n",
    "    \n",
    "    xs.append(overall)\n",
    "\n",
    "    # 0 1 2 #n=1\n",
    "    # 3 4 5 #n=2\n",
    "    # 6 7 8 #n=3\n",
    "    # 9 10 11 #stacked\n",
    "    # 12 #overall\n",
    "    return xs\n",
    "\n",
    "def via_lk_optical_flow_multi(frame, count=3):\n",
    "    frame['optical_flow'] = []\n",
    "    dfs = []\n",
    "    for i in range(1, count+1):\n",
    "        dfs.append(optical_flow(frame['_'], frame[str(i)], frame))\n",
    "    return analyze_lk_optical_flow_dfs(dfs)\n",
    "\n",
    "def debug_optical(df,img):\n",
    "    img = image_next.copy()\n",
    "    # we lose old arrow debugging with the df approach, sorry\n",
    "    #         if right_direction:\n",
    "    #             color=255\n",
    "    #             df.loc[i,'good'] = True\n",
    "    #         else:\n",
    "    #             color=130\n",
    "    #             df.loc[i,'good'] = False\n",
    "\n",
    "    #         if debugging:\n",
    "    #             img = cv2.arrowedLine(img,(int(x1),int(y1)),(int(x2),int(y2)), color, tipLength=.3)\n",
    "    #             img = cv2.circle(img,(int(x1),int(y1)),2,color, -1)\n",
    "    if len(df) == 0:\n",
    "        print(\"no useful points\")\n",
    "    else:\n",
    "        display(df.sort_values(by='|Vf|'))       \n",
    "        bins = list(range(0,101,10))\n",
    "        plt.rcParams['figure.figsize'] = [20, 5]\n",
    "        df['|Vf|'].hist(bins=bins)\n",
    "        df[df['good']==True]['|Vf|'].hist(bins=bins)\n",
    "        plt.show()\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = [20, 12]\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners = 100,\n",
    "    qualityLevel = 0.007,\n",
    "    minDistance = 20,\n",
    "    blockSize = 9,\n",
    "    #useHarrisDetector = True,\n",
    "    )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(\n",
    "    winSize  = (15,15),\n",
    "    maxLevel = 1,\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "    )\n",
    "\n",
    "def optical_flow(image, image_next, frame, debugging=False):\n",
    "    p0 = cv2.goodFeaturesToTrack(image, mask=None, **feature_params)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image, image_next, p0, None, **lk_params)\n",
    "    \n",
    "    points = []\n",
    "    for new, old in zip(p1[st==1],p0[st==1]):\n",
    "        x1, y1 = old.ravel()\n",
    "        x2, y2 = new.ravel()\n",
    "        points.append((x1,x2,y1,y2))\n",
    "    \n",
    "    df = pd.DataFrame(data=points, columns=('x1','x2','y1','y2'))\n",
    "    if debugging:\n",
    "        debug_optical(df,img)\n",
    "\n",
    "    frame['optical_flow'].append(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff based for stop detect\n",
    "def via_diff(f):\n",
    "    return [abs(cv2.subtract(f['_'],f['1']).sum())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Process frames\n",
    "def frames(file='../data/train.mp4'):\n",
    "    vidcap = cv2.VideoCapture(file)\n",
    "    while True:\n",
    "        success, image = vidcap.read()\n",
    "        if success:\n",
    "            yield {'orig': image, '_': image, 'xs':[]}\n",
    "        else:\n",
    "            return\n",
    "\n",
    "originy=None\n",
    "def crop(image, bottom=100, top=220):\n",
    "    # take of top and bottom\n",
    "    global originy\n",
    "    originy = image.shape[0] / 2 - top\n",
    "    return image[top:image.shape[0] - bottom,:]\n",
    "\n",
    "def lookahead(frames, count=3):\n",
    "    # add \"lookahead\" in keys '1', '2', ...\n",
    "    # repeats at the end to keep length len\n",
    "    fs = list()\n",
    "    \n",
    "    def _updated_f():\n",
    "        f = fs.pop(0)\n",
    "        f.update({str(n+1):f['_'] for n, f in enumerate(fs)})\n",
    "        return f \n",
    "        \n",
    "    for f in frames:\n",
    "        fs.append(f)\n",
    "        if len(fs) > count:\n",
    "            yield _updated_f()\n",
    "\n",
    "    for _ in range(count):\n",
    "        fs.append(f)\n",
    "        yield _updated_f()\n",
    "        \n",
    "def print_frame_keys(frames):\n",
    "    for f in frames:\n",
    "        print(repr(list(f.keys())))\n",
    "        yield f\n",
    "\n",
    "def view_frames(frames):\n",
    "    for f in frames:\n",
    "        for k in f.keys():\n",
    "            try:\n",
    "                cv2.imshow(k,f[k])\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            cv2.waitKey(0)\n",
    "        except KeyboardInterrupt:\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Stopping early, KeyboardInterrupt\")\n",
    "            return\n",
    "        yield f\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def persist_raw_optical_flow(frames):\n",
    "    import os\n",
    "    path = f'./data/{int(time())}'\n",
    "    os.makedirs(path)\n",
    "    for i, f in enumerate(frames):\n",
    "        for j, df in enumerate(f['optical_flow']):\n",
    "            df: pd.DataFrame\n",
    "            df.to_pickle(os.path.join(path,f'{i}_{j}.pkl'))\n",
    "        yield f\n",
    "\n",
    "class FeatureExtractor():\n",
    "    def __init__(self, frames_generator_maker):\n",
    "        self._frames = frames_generator_maker\n",
    "        self._steps = []\n",
    "    def add_step(self, step):\n",
    "        \"\"\"step(frames_iterator) yields-> [frame,frame,...]; you can filter or gather frames\"\"\"\n",
    "        if callable(step):\n",
    "            self._steps.append(step)\n",
    "    def add_processor(self, processor):\n",
    "        \"\"\"processor(img) returns-> img; frame['_'] is mutated\"\"\"\n",
    "        def _step(frames):\n",
    "            for f in frames:\n",
    "                f['_'] = processor(f['_'])\n",
    "                yield f\n",
    "        self.add_step(_step)\n",
    "    def add_analyzer(self, analyzer):\n",
    "        \"\"\"analyzer(frame) returns-> [x1,x2,...]; frame['_'] is forwarded untouched, features are collected\"\"\"\n",
    "        def _step(frames):\n",
    "            for f in frames:\n",
    "                f['xs'] += analyzer(f)\n",
    "                yield f\n",
    "        self.add_step(_step)\n",
    "\n",
    "    def __iter__(self):\n",
    "        pipeline = self._frames()\n",
    "        for s in self._steps:\n",
    "            pipeline = s(pipeline)\n",
    "        return pipeline\n",
    "    def _pprogress(self, count, force=False):\n",
    "        if force or time()-self._last>30:\n",
    "            self._last = time()\n",
    "            print(f\"{count+1} processed in {(time()-self._start)/60:2.1f} minutes\")\n",
    "    def extract_features(self):\n",
    "        self._start = time()\n",
    "        self._last = self._start\n",
    "        X = []\n",
    "        i=0\n",
    "        for i, f in enumerate(self):\n",
    "            X.append(f['xs'])\n",
    "            self._pprogress(i)\n",
    "        self._pprogress(i,True)\n",
    "        return X\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629 processed in 0.5 minutes\n",
      "1249 processed in 1.0 minutes\n",
      "1857 processed in 1.5 minutes\n",
      "2470 processed in 2.0 minutes\n",
      "3084 processed in 2.5 minutes\n",
      "3738 processed in 3.0 minutes\n",
      "4387 processed in 3.5 minutes\n",
      "5052 processed in 4.0 minutes\n",
      "5714 processed in 4.5 minutes\n",
      "6374 processed in 5.0 minutes\n",
      "7034 processed in 5.5 minutes\n",
      "7697 processed in 6.0 minutes\n",
      "8356 processed in 6.5 minutes\n",
      "8999 processed in 7.0 minutes\n",
      "9653 processed in 7.5 minutes\n",
      "10303 processed in 8.0 minutes\n",
      "10937 processed in 8.5 minutes\n",
      "11585 processed in 9.0 minutes\n",
      "12227 processed in 9.5 minutes\n",
      "12868 processed in 10.0 minutes\n",
      "13510 processed in 10.5 minutes\n",
      "14142 processed in 11.0 minutes\n",
      "14778 processed in 11.5 minutes\n",
      "15429 processed in 12.0 minutes\n",
      "16091 processed in 12.5 minutes\n",
      "16722 processed in 13.0 minutes\n",
      "17375 processed in 13.5 minutes\n",
      "18025 processed in 14.0 minutes\n",
      "18648 processed in 14.5 minutes\n",
      "19289 processed in 15.0 minutes\n",
      "19930 processed in 15.5 minutes\n",
      "20400 processed in 15.9 minutes\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureExtractor(frames)\n",
    "\n",
    "#fe.add_step(lambda g: islice(g, 17500, 20400, 1)) # limit frames (start, stop, step)\n",
    "#fe.add_step(lambda g: islice(g, 400, 420, 1)) # limit frames (start, stop, step)\n",
    "\n",
    "fe.add_processor(lambda img: crop(img, bottom=100, top=220))\n",
    "fe.add_processor(lambda img: cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
    "fe.add_processor(fix_perspective)\n",
    "fe.add_processor(lambda img: cv2.GaussianBlur(img,(7,7),0))\n",
    "\n",
    "fe.add_step(lambda frames: lookahead(frames, count=3))\n",
    "\n",
    "#fe.add_analyzer(via_lk_optical_flow)\n",
    "fe.add_analyzer(via_lk_optical_flow_multi)\n",
    "fe.add_analyzer(via_variance_of_laplacian)\n",
    "fe.add_analyzer(via_diff)\n",
    "\n",
    "#fe.add_step(persist_raw_optical_flow)\n",
    "#fe.add_step(print_frame_keys)\n",
    "#fe.add_step(view_frames)\n",
    "\n",
    "xs = fe.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_time_in_chunks(df, n):\n",
    "    \"\"\"Break df into n-lengths mini dfs\"\"\"\n",
    "    assert len(df) >= n*10, \"doesn't meet minimum number of chunks\"\n",
    "    assert (len(df) % n) == 0, \"all chunks equal size\"\n",
    "    \n",
    "    chunk_count = len(df) // n\n",
    "    chunks = []\n",
    "    for x in range(0, len(df), n):\n",
    "        chunks.append(df[x:x + n])\n",
    "    random.shuffle(chunks)\n",
    "    print(f\"Using {len(chunks):0d} chunks\")\n",
    "    return pd.concat(chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20301.000000</td>\n",
       "      <td>20199.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>20171.000000</td>\n",
       "      <td>20038.000000</td>\n",
       "      <td>20399.000000</td>\n",
       "      <td>19960.000000</td>\n",
       "      <td>19799.000000</td>\n",
       "      <td>20399.000000</td>\n",
       "      <td>20300.000000</td>\n",
       "      <td>20277.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>19907.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>2.040000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.052734</td>\n",
       "      <td>5.525136</td>\n",
       "      <td>4.799234</td>\n",
       "      <td>21.724671</td>\n",
       "      <td>5.542001</td>\n",
       "      <td>2.844092</td>\n",
       "      <td>21.518410</td>\n",
       "      <td>5.687407</td>\n",
       "      <td>2.333646</td>\n",
       "      <td>21.417903</td>\n",
       "      <td>5.424170</td>\n",
       "      <td>3.357223</td>\n",
       "      <td>21.750685</td>\n",
       "      <td>2.429951</td>\n",
       "      <td>3.254773</td>\n",
       "      <td>3.384131</td>\n",
       "      <td>2.060806e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.133754</td>\n",
       "      <td>4.117217</td>\n",
       "      <td>9.669150</td>\n",
       "      <td>15.673859</td>\n",
       "      <td>4.248105</td>\n",
       "      <td>7.581492</td>\n",
       "      <td>15.271258</td>\n",
       "      <td>4.529610</td>\n",
       "      <td>6.865346</td>\n",
       "      <td>15.371821</td>\n",
       "      <td>3.901604</td>\n",
       "      <td>7.012366</td>\n",
       "      <td>15.284451</td>\n",
       "      <td>1.381638</td>\n",
       "      <td>2.112268</td>\n",
       "      <td>1.639592</td>\n",
       "      <td>1.543139e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>-116.187047</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>-126.458439</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-99.169061</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>-114.883626</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.348827</td>\n",
       "      <td>0.441444</td>\n",
       "      <td>0.421173</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.168556</td>\n",
       "      <td>2.425897</td>\n",
       "      <td>-0.238537</td>\n",
       "      <td>8.194919</td>\n",
       "      <td>2.224346</td>\n",
       "      <td>-0.818561</td>\n",
       "      <td>8.350239</td>\n",
       "      <td>2.147118</td>\n",
       "      <td>-0.985925</td>\n",
       "      <td>8.177106</td>\n",
       "      <td>2.313584</td>\n",
       "      <td>-0.352002</td>\n",
       "      <td>8.562533</td>\n",
       "      <td>1.495517</td>\n",
       "      <td>1.848284</td>\n",
       "      <td>2.115873</td>\n",
       "      <td>1.280638e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.904147</td>\n",
       "      <td>4.502413</td>\n",
       "      <td>3.863911</td>\n",
       "      <td>17.847354</td>\n",
       "      <td>4.385355</td>\n",
       "      <td>2.245137</td>\n",
       "      <td>17.948092</td>\n",
       "      <td>4.433294</td>\n",
       "      <td>1.793814</td>\n",
       "      <td>17.581195</td>\n",
       "      <td>4.558648</td>\n",
       "      <td>2.688383</td>\n",
       "      <td>18.125114</td>\n",
       "      <td>2.148932</td>\n",
       "      <td>2.849210</td>\n",
       "      <td>3.103574</td>\n",
       "      <td>1.733775e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.406030</td>\n",
       "      <td>7.734051</td>\n",
       "      <td>9.793322</td>\n",
       "      <td>35.071106</td>\n",
       "      <td>8.178047</td>\n",
       "      <td>6.362307</td>\n",
       "      <td>34.640009</td>\n",
       "      <td>8.480785</td>\n",
       "      <td>5.344351</td>\n",
       "      <td>34.780746</td>\n",
       "      <td>8.106215</td>\n",
       "      <td>6.777629</td>\n",
       "      <td>35.137876</td>\n",
       "      <td>3.003370</td>\n",
       "      <td>4.121873</td>\n",
       "      <td>4.284229</td>\n",
       "      <td>2.377012e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.891515</td>\n",
       "      <td>38.534682</td>\n",
       "      <td>83.617086</td>\n",
       "      <td>77.726476</td>\n",
       "      <td>34.490408</td>\n",
       "      <td>52.578316</td>\n",
       "      <td>77.525239</td>\n",
       "      <td>39.584484</td>\n",
       "      <td>48.778914</td>\n",
       "      <td>73.523423</td>\n",
       "      <td>38.534682</td>\n",
       "      <td>49.815615</td>\n",
       "      <td>66.597995</td>\n",
       "      <td>14.013617</td>\n",
       "      <td>19.977022</td>\n",
       "      <td>23.558937</td>\n",
       "      <td>3.287497e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  20301.000000  20199.000000  20400.000000  20171.000000  20038.000000   \n",
       "mean      22.052734      5.525136      4.799234     21.724671      5.542001   \n",
       "std       16.133754      4.117217      9.669150     15.673859      4.248105   \n",
       "min        0.004153      0.002088   -116.187047      0.001527      0.000472   \n",
       "25%        8.168556      2.425897     -0.238537      8.194919      2.224346   \n",
       "50%       17.904147      4.502413      3.863911     17.847354      4.385355   \n",
       "75%       35.406030      7.734051      9.793322     35.071106      8.178047   \n",
       "max       73.891515     38.534682     83.617086     77.726476     34.490408   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  20399.000000  19960.000000  19799.000000  20399.000000  20300.000000   \n",
       "mean       2.844092     21.518410      5.687407      2.333646     21.417903   \n",
       "std        7.581492     15.271258      4.529610      6.865346     15.371821   \n",
       "min     -126.458439      0.002043      0.000354    -99.169061      0.002558   \n",
       "25%       -0.818561      8.350239      2.147118     -0.985925      8.177106   \n",
       "50%        2.245137     17.948092      4.433294      1.793814     17.581195   \n",
       "75%        6.362307     34.640009      8.480785      5.344351     34.780746   \n",
       "max       52.578316     77.525239     39.584484     48.778914     73.523423   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  20277.000000  20400.000000  19907.000000  20400.000000  20400.000000   \n",
       "mean       5.424170      3.357223     21.750685      2.429951      3.254773   \n",
       "std        3.901604      7.012366     15.284451      1.381638      2.112268   \n",
       "min        0.001149   -114.883626      0.032415      0.348827      0.441444   \n",
       "25%        2.313584     -0.352002      8.562533      1.495517      1.848284   \n",
       "50%        4.558648      2.688383     18.125114      2.148932      2.849210   \n",
       "75%        8.106215      6.777629     35.137876      3.003370      4.121873   \n",
       "max       38.534682     49.815615     66.597995     14.013617     19.977022   \n",
       "\n",
       "                 15            16  \n",
       "count  20400.000000  2.040000e+04  \n",
       "mean       3.384131  2.060806e+05  \n",
       "std        1.639592  1.543139e+05  \n",
       "min        0.421173  0.000000e+00  \n",
       "25%        2.115873  1.280638e+05  \n",
       "50%        3.103574  1.733775e+05  \n",
       "75%        4.284229  2.377012e+05  \n",
       "max       23.558937  3.287497e+06  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('../data/train.txt', header=None)\n",
    "X = pd.DataFrame(xs)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[12] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e0ad1f093796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 12 #overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[12] not in index'"
     ]
    }
   ],
   "source": [
    "#X.fillna(value=0, inplace=True)\n",
    "X.fillna(method='pad', inplace=True)\n",
    "#X=X[[0,2,4,3,'024']] # 1,2,3 frame Vf and 2-frame std, and linear average of the three Vf\n",
    "    # 0 1 2 #n=1\n",
    "    # 3 4 5 #n=2\n",
    "    # 6 7 8 #n=3\n",
    "    # 9 10 11 #stacked\n",
    "    # 12 #overall\n",
    "X=X[[0,1,2,  3,4,5,  6,7,8  ,9]]\n",
    "X=X[[3,4,5,9,12]]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 chunks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>50.531488</td>\n",
       "      <td>11.349832</td>\n",
       "      <td>13.030548</td>\n",
       "      <td>48.133533</td>\n",
       "      <td>13.797435</td>\n",
       "      <td>5.190921</td>\n",
       "      <td>47.457343</td>\n",
       "      <td>18.171526</td>\n",
       "      <td>13.689880</td>\n",
       "      <td>47.896641</td>\n",
       "      <td>23.083131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>56.814117</td>\n",
       "      <td>8.824110</td>\n",
       "      <td>-10.789770</td>\n",
       "      <td>46.110387</td>\n",
       "      <td>15.595254</td>\n",
       "      <td>14.968960</td>\n",
       "      <td>43.055168</td>\n",
       "      <td>11.818676</td>\n",
       "      <td>1.571956</td>\n",
       "      <td>48.989580</td>\n",
       "      <td>23.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>40.936344</td>\n",
       "      <td>16.971879</td>\n",
       "      <td>-13.327786</td>\n",
       "      <td>59.355430</td>\n",
       "      <td>15.270372</td>\n",
       "      <td>-6.011798</td>\n",
       "      <td>45.324238</td>\n",
       "      <td>18.465573</td>\n",
       "      <td>1.260840</td>\n",
       "      <td>50.130520</td>\n",
       "      <td>23.097455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>54.848185</td>\n",
       "      <td>10.624068</td>\n",
       "      <td>8.024640</td>\n",
       "      <td>49.886347</td>\n",
       "      <td>16.514924</td>\n",
       "      <td>10.264162</td>\n",
       "      <td>38.177946</td>\n",
       "      <td>17.449448</td>\n",
       "      <td>4.096790</td>\n",
       "      <td>52.305665</td>\n",
       "      <td>23.070734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>57.265716</td>\n",
       "      <td>16.176728</td>\n",
       "      <td>5.337735</td>\n",
       "      <td>49.003952</td>\n",
       "      <td>20.111635</td>\n",
       "      <td>13.704181</td>\n",
       "      <td>38.618794</td>\n",
       "      <td>14.781997</td>\n",
       "      <td>-0.926672</td>\n",
       "      <td>50.562096</td>\n",
       "      <td>23.075198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>12.338974</td>\n",
       "      <td>3.846167</td>\n",
       "      <td>5.793846</td>\n",
       "      <td>10.587193</td>\n",
       "      <td>3.327510</td>\n",
       "      <td>3.191908</td>\n",
       "      <td>12.647903</td>\n",
       "      <td>3.495186</td>\n",
       "      <td>1.696768</td>\n",
       "      <td>11.425903</td>\n",
       "      <td>9.380622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>12.501878</td>\n",
       "      <td>3.337351</td>\n",
       "      <td>4.935507</td>\n",
       "      <td>10.712543</td>\n",
       "      <td>2.569409</td>\n",
       "      <td>5.314723</td>\n",
       "      <td>11.238910</td>\n",
       "      <td>3.117254</td>\n",
       "      <td>11.026762</td>\n",
       "      <td>11.282899</td>\n",
       "      <td>9.331728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>11.704848</td>\n",
       "      <td>2.571974</td>\n",
       "      <td>3.126681</td>\n",
       "      <td>10.013975</td>\n",
       "      <td>3.259235</td>\n",
       "      <td>4.206196</td>\n",
       "      <td>12.077608</td>\n",
       "      <td>2.000770</td>\n",
       "      <td>-0.167175</td>\n",
       "      <td>11.271269</td>\n",
       "      <td>9.309530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8974</th>\n",
       "      <td>11.817096</td>\n",
       "      <td>3.320771</td>\n",
       "      <td>3.294933</td>\n",
       "      <td>9.742487</td>\n",
       "      <td>2.836865</td>\n",
       "      <td>6.507989</td>\n",
       "      <td>12.888727</td>\n",
       "      <td>2.264141</td>\n",
       "      <td>2.999764</td>\n",
       "      <td>10.964815</td>\n",
       "      <td>9.311108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>11.326493</td>\n",
       "      <td>4.227227</td>\n",
       "      <td>7.917873</td>\n",
       "      <td>13.419776</td>\n",
       "      <td>4.225330</td>\n",
       "      <td>2.412919</td>\n",
       "      <td>15.111000</td>\n",
       "      <td>2.582429</td>\n",
       "      <td>-2.265239</td>\n",
       "      <td>13.302720</td>\n",
       "      <td>9.254130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20400 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "2040  50.531488  11.349832  13.030548  48.133533  13.797435   5.190921   \n",
       "2041  56.814117   8.824110 -10.789770  46.110387  15.595254  14.968960   \n",
       "2042  40.936344  16.971879 -13.327786  59.355430  15.270372  -6.011798   \n",
       "2043  54.848185  10.624068   8.024640  49.886347  16.514924  10.264162   \n",
       "2044  57.265716  16.176728   5.337735  49.003952  20.111635  13.704181   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "8971  12.338974   3.846167   5.793846  10.587193   3.327510   3.191908   \n",
       "8972  12.501878   3.337351   4.935507  10.712543   2.569409   5.314723   \n",
       "8973  11.704848   2.571974   3.126681  10.013975   3.259235   4.206196   \n",
       "8974  11.817096   3.320771   3.294933   9.742487   2.836865   6.507989   \n",
       "8975  11.326493   4.227227   7.917873  13.419776   4.225330   2.412919   \n",
       "\n",
       "              6          7          8          9          y  \n",
       "2040  47.457343  18.171526  13.689880  47.896641  23.083131  \n",
       "2041  43.055168  11.818676   1.571956  48.989580  23.079400  \n",
       "2042  45.324238  18.465573   1.260840  50.130520  23.097455  \n",
       "2043  38.177946  17.449448   4.096790  52.305665  23.070734  \n",
       "2044  38.618794  14.781997  -0.926672  50.562096  23.075198  \n",
       "...         ...        ...        ...        ...        ...  \n",
       "8971  12.647903   3.495186   1.696768  11.425903   9.380622  \n",
       "8972  11.238910   3.117254  11.026762  11.282899   9.331728  \n",
       "8973  12.077608   2.000770  -0.167175  11.271269   9.309530  \n",
       "8974  12.888727   2.264141   2.999764  10.964815   9.311108  \n",
       "8975  15.111000   2.582429  -2.265239  13.302720   9.254130  \n",
       "\n",
       "[20400 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy = X.copy()\n",
    "Xy['y'] = y\n",
    "\n",
    "chunksize = 2040 # ten chunks\n",
    "chunksize = 204*2 # 50\n",
    "Xy = shuffle_time_in_chunks(Xy, chunksize)\n",
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using testcount = 8976\n",
      "Percent test    = 0.44\n"
     ]
    }
   ],
   "source": [
    "def find_testcount(test_df, fraction_testset=0.3):\n",
    "    chunks = 1\n",
    "    while True:\n",
    "        chunks += 1\n",
    "        testcount = chunksize * chunks\n",
    "        if testcount/len(test_df)>fraction_testset:\n",
    "            break\n",
    "    print(f\"using testcount = {testcount}\")\n",
    "    return testcount\n",
    "    \n",
    "testcount = find_testcount(Xy, .43)\n",
    "\n",
    "Xy_train, Xy_test = train_test_split(Xy, test_size=testcount,shuffle=False)\n",
    "Xy_train, Xy_test = Xy_train.copy(deep=True), Xy_test.copy(deep=True)\n",
    "print(\"Percent test    =\", testcount/len(Xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "m_dum = DummyRegressor(strategy='mean')\n",
    "\n",
    "m_ensemble = StackingRegressor([\n",
    "   ('svr', SVR(C=.3)),\n",
    "   ('rf', RandomForestRegressor(n_estimators=60)),\n",
    "   #('mlp', MLPRegressor(shuffle=False, alpha=0.1)),\n",
    "   ])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    #('poly', PolynomialFeatures(interaction_only=False, include_bias=False)),\n",
    "    #'reduce_dims', PCA(n_components=4)),\n",
    "    #('svr', SVR(C=2)),\n",
    "    #('rf', RandomForestRegressor()),\n",
    "    #'mlp', MLPRegressor(shuffle=False, alpha=0.1)),\n",
    "    #('br', BayesianRidge()),\n",
    "    ('stack', m_ensemble),\n",
    "    #('lin', LinearRegression()),\n",
    "    ])\n",
    "\n",
    "# # Training classifiers\n",
    "# reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "# reg2 = RandomForestRegressor(random_state=1, n_estimators=10)\n",
    "# reg3 = LinearRegression()\n",
    "# ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "# BaysianRidge\n",
    "# MLP NN\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'stack__svr__C':[0.0001, 0.001,.01, .1, .3, .9, 2, 4, 10, 15, 20, 50, 100, 200],\n",
    "    'stack__rf__n_estimators': [3, 5, 8, 10, 20, 50, 100, 150],\n",
    "    #'stack__rf__max_depth': None,\n",
    "    \n",
    "    #'svr__C':[10, 20, 30, 40, 70, 120],\n",
    "    #'mlp__alpha':[0.0001, 0.001, 0.01],\n",
    "    #'svr__C':[.3],RandomForestRegressor\n",
    "    #'svr__gamma':[0.006/4, 0.006/2,0.006,0.006*2],\n",
    "    }\n",
    "grid = GridSearchCV(pipe, parameters, verbose=10, n_jobs=8, cv=7)\n",
    "\n",
    "m_real = grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 112 candidates, totalling 784 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed: 41.9min\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed: 58.5min\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed: 62.0min\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed: 65.0min\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed: 70.7min\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed: 82.2min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 86.7min\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed: 93.0min\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed: 109.5min\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed: 116.9min\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed: 124.8min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed: 141.1min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed: 150.4min\n"
     ]
    }
   ],
   "source": [
    "m_dum.fit(Xy_train[X.columns], Xy_train['y'])\n",
    "m_real.fit(Xy_train[X.columns], Xy_train['y'])\n",
    "try:\n",
    "    print(m_real.best_estimator_)\n",
    "except:\n",
    "    print(m_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-16fd8e9bda6c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-16fd8e9bda6c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    grid.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate full original df\n",
    "Xy_test.loc[:,'is_test'] = True\n",
    "Xy_train.loc[:,'is_test'] = False\n",
    "Xy2 = pd.concat([Xy_test,Xy_train]).sort_index()\n",
    "\n",
    "# get predictions\n",
    "Xy2['dum'] = m_dum.predict(Xy2[X.columns])\n",
    "Xy2['pred'] = m_real.predict(Xy2[X.columns])\n",
    "\n",
    "# for convience\n",
    "Xy2_test_ix = Xy2['is_test'] == True\n",
    "Xy2_train_ix = Xy2['is_test'] == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smooth based on distribution of acceleration in training set\n",
    "idea use kalman filter based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune a kalman filter\n",
    "from pykalman import KalmanFilter\n",
    "em_vars = [\n",
    "     #'transition_covariance',\n",
    "     'observation_covariance',\n",
    "     'initial_state_mean', 'initial_state_covariance']\n",
    "\n",
    "T = np.array([[.0009]]) # smaller is more resistance to acceleration\n",
    "\n",
    "kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1, transition_covariance=T)\n",
    "kf = kf.em(Xy2.loc[Xy2_train_ix,'y'].values, n_iter=0, em_vars=em_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply kalman\n",
    "Xy2.loc[Xy2_test_ix,'pred_kf'] = kf.smooth(Xy2.loc[Xy2_test_ix,'pred'].values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# never below 0\n",
    "Xy2.loc[Xy2['pred_kf'] < 0.0,'pred_kf'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = Xy2.loc[Xy2_train_ix,'y'].mean()\n",
    "target_mean = Xy2['y'].mean() # for full comparison, overly optimistic though\n",
    "\n",
    "NoMLCol = 9\n",
    "\n",
    "_ = kf.smooth(Xy2[NoMLCol].values)[0]\n",
    "Xy2['NoML_kf'] = _ * target_mean/_.mean()\n",
    "Xy2['NoML_scaled'] = Xy2[NoMLCol] * target_mean/Xy2[NoMLCol].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [100, 12]\n",
    "plt.gca().set_xlim((0,len(Xy2)))\n",
    "def plot_Xy2(ix_mask, column, **kwargs):\n",
    "    try:\n",
    "        if ix_mask is None:\n",
    "            df = Xy2.loc[:,column]\n",
    "        else:\n",
    "            df = Xy2.loc[ix_mask, column]\n",
    "        plt.plot(df.index, df.values, **kwargs)\n",
    "    except KeyError:\n",
    "        print(f\"Skipping {column}\")\n",
    "    \n",
    "#plot_Xy2(Xy2_test_ix, 'pred', marker='o', linewidth=0.0, color='green', alpha=.1)\n",
    "#plot_Xy2(Xy2_train_ix, 'pred', marker='o', linewidth=0.0, color='purple', alpha=.1)\n",
    "plot_Xy2(None, 'NoML_scaled', marker='o', linewidth=0.0, color='yellow', alpha=.1)\n",
    "plot_Xy2(None, 'NoML_kf', marker='', linewidth=1.5, color='orange')\n",
    "plot_Xy2(None, '1_thresh', marker='', linewidth=0.5, color='blue')\n",
    "plot_Xy2(None, 'y', marker='', linewidth=1.4, color='red')\n",
    "plot_Xy2(Xy2_test_ix, 'pred_kf', marker='o', linewidth=0.0, color='green', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_line(ix_mask, column='dum'):\n",
    "    if ix_mask is not None:\n",
    "        Xy = Xy2[ix_mask]\n",
    "    else:\n",
    "        Xy = Xy2\n",
    "    err = mean_squared_error(Xy['y'], Xy[column])\n",
    "    print(f\"{err:0.1f}\", end='\\t')\n",
    "\n",
    "print(f\"dummy\\ttest\\ttrain\\ttest_kf\\tNoML\")\n",
    "print_summary_line(Xy2_test_ix,'dum')\n",
    "print_summary_line(Xy2_test_ix,'pred')\n",
    "print_summary_line(Xy2_train_ix,'pred')\n",
    "print_summary_line(Xy2_test_ix,'pred_kf')\n",
    "print_summary_line(None,'NoML_kf') # 10.3 was best, gaussian made it 7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummy\ttest\ttrain\ttest_kf\tNoML\n",
    "69.6\t16.6\t5.6\t7.7\t13.5\t\n",
    "\n",
    "^^^^got this,,,,,why>???????? trying to lower absurity ceiling again 260->160\n",
    "maybe column multiplication should be done _after_ forward fillign/padding Xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NoML'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NoML'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4b6908dc9644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NoML'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.plot(df.index, df.values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/y2kspeed-NWwxFr2U/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NoML'"
     ]
    }
   ],
   "source": [
    "df = Xy2.copy()\n",
    "df = df.groupby(np.arange(len(df.index)) // 100).mean()\n",
    "df['loss']=abs(df['y']-df['NoML_kf'])\n",
    "#plt.plot(df.index, df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='loss', ascending=False).head(10).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure pipeline is set up the same in both places\n",
    "columns_used_to_train = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feo = FeatureExtractor(lambda: frames(file='../data/train.mp4'))\n",
    "\n",
    "#feo.add_step(lambda g: islice(g, 17500, 20400, 1)) # limit frames (start, stop, step)\n",
    "#feo.add_step(lambda g: islice(g, 400, 420, 1)) # limit frames (start, stop, step)\n",
    "\n",
    "feo.add_processor(lambda img: crop(img, bottom=100, top=220))\n",
    "feo.add_processor(lambda img: cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
    "feo.add_processor(fix_perspective)\n",
    "feo.add_processor(lambda img: cv2.GaussianBlur(img,(7,7),0))\n",
    "\n",
    "feo.add_step(lambda frames: lookahead(frames, count=3))\n",
    "\n",
    "#feo.add_analyzer(via_lk_optical_flow)\n",
    "feo.add_analyzer(via_lk_optical_flow_multi)\n",
    "feo.add_analyzer(via_variance_of_laplacian)\n",
    "feo.add_analyzer(via_diff)\n",
    "\n",
    "#feo.add_step(print_frame_keys)\n",
    "#feo.add_step(view_frames)\n",
    "\n",
    "xso = fe.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_used_to_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
